{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b11bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Loads variables from .env into environment\n",
    "\n",
    "from google.adk.agents import LlmAgent, SequentialAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.tools import google_search\n",
    "from google.genai import types\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7b6a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if GOOGLE_API_KEY:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"âœ… Gemini API key setup complete.\")\n",
    "else:\n",
    "    print(\"ðŸ”‘ Authentication Error: 'GOOGLE_API_KEY' not found in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ca2ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "async def run_session(\n",
    "    runner_instance: Runner, user_queries: list[str] | str, session_id: str = \"default\"\n",
    "):\n",
    "    \"\"\"Helper function to run queries in a session and display responses.\"\"\"\n",
    "    print(f\"\\n### Session: {session_id}\")\n",
    "\n",
    "    # Create or retrieve session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "\n",
    "    # Convert single query to list\n",
    "    if isinstance(user_queries, str):\n",
    "        user_queries = [user_queries]\n",
    "\n",
    "    # Process each query\n",
    "    for query in user_queries:\n",
    "        print(f\"\\nUser > {query}\")\n",
    "        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "        # Stream agent response\n",
    "        async for event in runner_instance.run_async(\n",
    "            user_id=USER_ID, session_id=session.id, new_message=query_content\n",
    "        ):\n",
    "            if event.is_final_response() and event.content and event.content.parts:\n",
    "                text = event.content.parts[0].text\n",
    "                if text and text != \"None\":\n",
    "                    print(f\"Model: > {text}\")\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3332bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_session(\n",
    "    runner_instance: Runner,\n",
    "    user_queries: list[str] | str = None,\n",
    "    session_name: str = \"default\",\n",
    "    last_agent_only: bool = False,\n",
    "):\n",
    "    print(f\"\\n ### Session: {session_name}\")\n",
    "\n",
    "    # Get app name from the Runner\n",
    "    app_name = runner_instance.app_name\n",
    "\n",
    "    # Attempt to create a new session or retrieve an existing one\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "\n",
    "    # Process queries if provided\n",
    "    if user_queries:\n",
    "        # Convert single query to list for uniform processing\n",
    "        if type(user_queries) == str:\n",
    "            user_queries = [user_queries]\n",
    "\n",
    "        # Process each query in the list sequentially\n",
    "        for query in user_queries:\n",
    "            print(f\"\\nUser > {query}\")\n",
    "\n",
    "            # Convert the query string to the ADK Content format\n",
    "            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "            responses = []  # Buffer to collect responses with agent names\n",
    "\n",
    "            # Stream the agent's response asynchronously\n",
    "            async for event in runner_instance.run_async(\n",
    "                user_id=USER_ID, session_id=session.id, new_message=query\n",
    "            ):\n",
    "                # Check if the event contains valid content\n",
    "                if event.content and event.content.parts:\n",
    "                    # Filter out empty or \"None\" responses before printing\n",
    "                    if (\n",
    "                        event.content.parts[0].text != \"None\"\n",
    "                        and event.content.parts[0].text\n",
    "                    ):\n",
    "                        # Get agent name from author attribute\n",
    "                        agent_name = getattr(event, 'author', 'Unknown Agent')\n",
    "\n",
    "                        if last_agent_only:\n",
    "                            # Collect all responses with agent names\n",
    "                            responses.append({\n",
    "                                'agent': agent_name,\n",
    "                                'text': event.content.parts[0].text\n",
    "                            })\n",
    "                        else:\n",
    "                            # Print all responses\n",
    "                            print(f\"{agent_name} > \", event.content.parts[0].text)\n",
    "\n",
    "            # Print only the last response if filtering\n",
    "            if last_agent_only and responses:\n",
    "                last_response = responses[-1]\n",
    "                print(f\"{last_response['agent']} > \", last_response['text'])\n",
    "    else:\n",
    "        print(\"No queries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba2460f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Callback created.\n"
     ]
    }
   ],
   "source": [
    "async def auto_save_to_memory(callback_context):\n",
    "    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
    "    await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
    "        callback_context._invocation_context.session\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"âœ… Callback created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48d3848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8621ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Research Agent\n",
    "research_agent = LlmAgent(\n",
    "    name=\"research_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "    You are a Research Agent. Your task is to gather comprehensive information on topics provided by the user.\n",
    "    Follow these guidelines:\n",
    "    1. Understand the topic thoroughly before starting your research.\n",
    "    2. Use the Google Search tool to find relevant and credible sources.\n",
    "    3. Summarize the key points from your findings in a clear and concise manner\n",
    "    \n",
    "    If the user asks for something outside of research related to a job, politely inform them that your role is limited to research tasks only. \n",
    "    \"\"\",\n",
    "    # Before you start generating any output, mention your name as 'Research Agent' for the user to know.\n",
    "    tools=[google_search],  # NOTE: Do I need to add preload_memory here?\n",
    "    output_key=\"research_summary\", \n",
    "    after_agent_callback=auto_save_to_memory,  # Saves after each turn!\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38a88831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Mentor Agent\n",
    "mentor_agent = LlmAgent(\n",
    "    name=\"mentor_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "    You are a Mentor Agent. Your role is to provide guidance and support to users based on the research summaries provided: {research_summary}.\n",
    "    \n",
    "    Your goal is to create a program to advise the user on actions to follow to achieve in their transition to the researched career path.\n",
    "    \"\"\",\n",
    "    # Before you start generating any output, mention your name as 'Mentor Agent' for the user to know.\n",
    "    output_key=\"career_advice\",\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "829dcc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Root Agent to orchestrate the workflow\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"CareerPathPipeline\",\n",
    "    sub_agents=[research_agent, mentor_agent],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a273a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Stateful agent initialized!\n",
      "   - Application: default\n",
      "   - User: default\n",
      "   - Using: InMemorySessionService\n"
     ]
    }
   ],
   "source": [
    "APP_NAME = \"default\"  # Application\n",
    "USER_ID = \"default\"  # User\n",
    "SESSION = \"default\"  # Session\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "# Step 2: Set up Session Management\n",
    "# InMemorySessionService stores conversations in RAM (temporary)\n",
    "session_service = InMemorySessionService()\n",
    "memory_service = InMemoryMemoryService()  # ADK's built-in Memory Service for development and testing\n",
    "\n",
    "# Step 3: Create the Runner\n",
    "runner = Runner(\n",
    "    agent=root_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    "    )\n",
    "\n",
    "print(\"âœ… Stateful agent initialized!\")\n",
    "print(f\"   - Application: {APP_NAME}\")\n",
    "print(f\"   - User: {USER_ID}\")\n",
    "print(f\"   - Using: {session_service.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44258e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c97642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cded084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: stateful-agentic-session\n",
      "\n",
      "User > DO YOU REMEMBER our discussion?\n",
      "mentor_agent >  As a large language model, I don't have the ability to recall past conversations. Each interaction is treated as new.\n",
      "\n",
      "However, I am ready to assist you with your career transition. Please tell me about the career path you are interested in, and I will use my research capabilities to provide you with a program of actions to help you achieve your goal.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\n",
    "        # \"I am working as a product manager. I want to transition to data science\"\n",
    "        \"DO YOU REMEMBER our discussion?\"\n",
    "    ],\n",
    "    session_name=\"stateful-agentic-session\",\n",
    "    last_agent_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a633106",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_session_debug(\n",
    "    runner_instance: Runner,\n",
    "    user_queries: list[str] | str = None,\n",
    "    session_name: str = \"default\",\n",
    "):\n",
    "    print(f\"\\n ### Session: {session_name}\")\n",
    "\n",
    "    app_name = runner_instance.app_name\n",
    "\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "\n",
    "    if user_queries:\n",
    "        if type(user_queries) == str:\n",
    "            user_queries = [user_queries]\n",
    "\n",
    "        for query in user_queries:\n",
    "            print(f\"\\nUser > {query}\")\n",
    "            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "            async for event in runner_instance.run_async(\n",
    "                user_id=USER_ID, session_id=session.id, new_message=query\n",
    "            ):\n",
    "                if event.content and event.content.parts:\n",
    "                    if event.content.parts[0].text != \"None\" and event.content.parts[0].text:\n",
    "                        # Debug: print all event attributes\n",
    "                        print(\"\\n=== EVENT DEBUG ===\")\n",
    "                        print(f\"Event type: {type(event)}\")\n",
    "                        print(f\"Event attributes: {dir(event)}\")\n",
    "                        print(f\"Event dict (if available): {event.__dict__ if hasattr(event, '__dict__') else 'No __dict__'}\")\n",
    "                        print(\"==================\\n\")\n",
    "                        break  # Only debug first event\n",
    "            break  # Only debug first query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2b341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e0cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d1ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7432a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812b75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828da6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
