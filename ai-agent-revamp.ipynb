{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Career Advisor Agent - Revamped with LoopAgent\n",
    "\n",
    "This notebook implements an interactive career advisor using:\n",
    "- **LoopAgent** for interactive intake (gathering user information)\n",
    "- **SequentialAgent** for the main pipeline (research + mentoring)\n",
    "- **Memory** for cross-session context\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "User Query\n",
    "    â†“\n",
    "Intake Loop (asks questions until profile complete)\n",
    "    â†“\n",
    "Research Agent (searches for career transition info)\n",
    "    â†“\n",
    "Mentor Agent (creates personalized action plan)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from google.adk.agents import LlmAgent, SequentialAgent, LoopAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.tools import google_search, preload_memory, FunctionTool\n",
    "from google.genai import types\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API key\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if GOOGLE_API_KEY:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"âœ… Gemini API key setup complete.\")\n",
    "else:\n",
    "    print(\"ðŸ”‘ Authentication Error: 'GOOGLE_API_KEY' not found in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "APP_NAME = \"career_advisor\"\n",
    "USER_ID = \"default\"\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "# Retry configuration\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,\n",
    "    exp_base=7,\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],\n",
    ")\n",
    "\n",
    "print(\"âœ… Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for running sessions\n",
    "async def run_session(\n",
    "    runner_instance: Runner,\n",
    "    user_queries: list[str] | str = None,\n",
    "    session_name: str = \"default\",\n",
    "    show_all_agents: bool = False,\n",
    "):\n",
    "    \"\"\"Run queries in a session and display agent responses.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Session: {session_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    app_name = runner_instance.app_name\n",
    "\n",
    "    # Create or retrieve session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "        print(\"âœ… New session created\")\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "        print(\"âœ… Existing session retrieved\")\n",
    "\n",
    "    if user_queries:\n",
    "        if isinstance(user_queries, str):\n",
    "            user_queries = [user_queries]\n",
    "\n",
    "        for query in user_queries:\n",
    "            print(f\"\\nðŸ‘¤ User: {query}\")\n",
    "            print(f\"{'-'*60}\")\n",
    "\n",
    "            query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "            responses = []\n",
    "\n",
    "            async for event in runner_instance.run_async(\n",
    "                user_id=USER_ID, session_id=session.id, new_message=query_content\n",
    "            ):\n",
    "                if event.content and event.content.parts:\n",
    "                    text = event.content.parts[0].text\n",
    "                    if text and text != \"None\":\n",
    "                        agent_name = getattr(event, 'author', 'Agent')\n",
    "\n",
    "                        if show_all_agents:\n",
    "                            print(f\"\\nðŸ¤– {agent_name}:\")\n",
    "                            print(text)\n",
    "                        else:\n",
    "                            responses.append({'agent': agent_name, 'text': text})\n",
    "\n",
    "            # If not showing all, print only final response\n",
    "            if not show_all_agents and responses:\n",
    "                last = responses[-1]\n",
    "                print(f\"\\nðŸ¤– {last['agent']}:\")\n",
    "                print(last['text'])\n",
    "    else:\n",
    "        print(\"âš ï¸  No queries provided!\")\n",
    "\n",
    "print(\"âœ… Helper function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory callback\n",
    "async def auto_save_to_memory(callback_context):\n",
    "    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
    "    try:\n",
    "        agent_name = callback_context._invocation_context.agent.name\n",
    "        session = callback_context._invocation_context.session\n",
    "\n",
    "        await callback_context._invocation_context.memory_service.add_session_to_memory(session)\n",
    "\n",
    "        print(f\"ðŸ’¾ Saved {agent_name} output to memory\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Warning: Failed to save to memory: {e}\")\n",
    "\n",
    "print(\"âœ… Callback created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate_user_profile(\n",
    "    current_role: str,\n",
    "    years_experience: int,\n",
    "    target_role: str,\n",
    "    time_commitment_hours: int = 10\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Validates that all required user profile information has been collected.\n",
    "    \n",
    "    Args:\n",
    "        current_role: The user's current job role\n",
    "        years_experience: Years of experience in current role (0-50)\n",
    "        target_role: The role the user wants to transition to\n",
    "        time_commitment_hours: Hours per week available for learning (1-168)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with status and message\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if not current_role or len(current_role.strip()) < 2:\n",
    "        return {\"status\": \"incomplete\", \"message\": \"Current role is missing or invalid\"}\n",
    "    \n",
    "    if not target_role or len(target_role.strip()) < 2:\n",
    "        return {\"status\": \"incomplete\", \"message\": \"Target role is missing or invalid\"}\n",
    "    \n",
    "    if not isinstance(years_experience, int) or years_experience < 0 or years_experience > 50:\n",
    "        return {\"status\": \"invalid\", \"message\": \"Years of experience must be a number between 0 and 50\"}\n",
    "    \n",
    "    if not isinstance(time_commitment_hours, int) or time_commitment_hours < 1 or time_commitment_hours > 168:\n",
    "        return {\"status\": \"invalid\", \"message\": \"Time commitment must be between 1 and 168 hours per week\"}\n",
    "    \n",
    "    # All validations passed\n",
    "    return {\n",
    "        \"status\": \"complete\",\n",
    "        \"message\": f\"âœ… Profile complete! Ready to research transition from {current_role} to {target_role}.\",\n",
    "        \"profile\": {\n",
    "            \"current_role\": current_role,\n",
    "            \"years_experience\": years_experience,\n",
    "            \"target_role\": target_role,\n",
    "            \"time_commitment_hours\": time_commitment_hours\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exit function for loop\n",
    "def exit_intake_loop():\n",
    "    \"\"\"Exit the intake loop when profile is complete.\"\"\"\n",
    "    return {\"status\": \"profile_complete\", \"message\": \"Proceeding to research and mentoring...\"}\n",
    "\n",
    "print(\"âœ… Validation and exit functions created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Agent - Asks one question at a time\n",
    "question_agent = LlmAgent(\n",
    "    name=\"question_agent\",\n",
    "    model=Gemini(model=MODEL_NAME, retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "    You are a friendly Question Agent gathering information for career transition planning.\n",
    "    \n",
    "    Required information (4 items):\n",
    "    1. current_role - User's current job/position\n",
    "    2. years_experience - Years in current role (must be a NUMBER)\n",
    "    3. target_role - Role they want to transition to\n",
    "    4. time_commitment_hours - Hours per week for learning (must be a NUMBER, default: 10)\n",
    "    \n",
    "    PROCESS:\n",
    "    - Review the conversation history to see what's already been provided\n",
    "    - Check preload_memory for any past information\n",
    "    - If something is missing, ask ONE friendly question for the next missing piece\n",
    "    - If you receive an answer, acknowledge it briefly and naturally\n",
    "    - DO NOT call any validation tools - that's the next agent's job\n",
    "    \n",
    "    IMPORTANT:\n",
    "    - Ask questions conversationally, not like a form\n",
    "    - Be warm and encouraging\n",
    "    - Only ask ONE question at a time\n",
    "    - If the user provides multiple pieces of info at once, acknowledge all of them\n",
    "    \"\"\",\n",
    "    tools=[preload_memory],\n",
    "    output_key=\"conversation_state\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Question agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validator Agent - Checks if we have all info and exits loop if complete\n",
    "validator_agent = LlmAgent(\n",
    "    name=\"validator_agent\",\n",
    "    model=Gemini(model=MODEL_NAME, retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "    You are a Validator Agent. Review the conversation to determine if all required profile information has been collected.\n",
    "    \n",
    "    Required information:\n",
    "    1. current_role (string)\n",
    "    2. years_experience (integer/number)\n",
    "    3. target_role (string)\n",
    "    4. time_commitment_hours (integer/number)\n",
    "    \n",
    "    CRITICAL DECISION LOGIC:\n",
    "    \n",
    "    IF you have all 4 pieces of information:\n",
    "        1. Call validate_user_profile() with the gathered data\n",
    "        2. If validation returns \"complete\":\n",
    "           - Call exit_intake_loop() IMMEDIATELY\n",
    "           - Output the validated profile summary\n",
    "        3. If validation returns \"incomplete\" or \"invalid\":\n",
    "           - Do nothing, let the loop continue\n",
    "    \n",
    "    IF you're missing any information:\n",
    "        - Do NOT call any functions\n",
    "        - Just output a brief acknowledgment\n",
    "        - The loop will continue and question_agent will ask the next question\n",
    "    \n",
    "    IMPORTANT RULES:\n",
    "    - years_experience and time_commitment_hours MUST be integers (whole numbers)\n",
    "    - If user says \"five years\", convert to 5\n",
    "    - If user says \"about 10 hours\" or \"10-15 hours\", use 10\n",
    "    - You MUST call exit_intake_loop() when profile is complete\n",
    "    \"\"\",\n",
    "    tools=[FunctionTool(validate_user_profile), FunctionTool(exit_intake_loop)],\n",
    "    output_key=\"user_profile\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Validator agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intake Loop - Combines question and validator agents\n",
    "intake_loop = LoopAgent(\n",
    "    name=\"IntakeLoop\",\n",
    "    sub_agents=[question_agent, validator_agent],\n",
    "    max_iterations=10,  # Safety limit to prevent infinite loops\n",
    ")\n",
    "\n",
    "print(\"âœ… Intake loop created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Agent\n",
    "research_agent = LlmAgent(\n",
    "    name=\"research_agent\",\n",
    "    model=Gemini(model=MODEL_NAME, retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "    You are a Research Agent specialized in career transitions.\n",
    "    \n",
    "    USER PROFILE:\n",
    "    {user_profile}\n",
    "    \n",
    "    Your task:\n",
    "    1. Use the Google Search tool to research the target career path from the user profile\n",
    "    2. Focus on: required skills, typical career progression, salary ranges, and job market demand\n",
    "    3. Search for: online courses, certifications, and learning resources\n",
    "    4. Look for: success stories of people who made similar transitions\n",
    "    \n",
    "    Output format:\n",
    "    ## Key Skills Required\n",
    "    [List 5-7 essential skills with brief descriptions]\n",
    "    \n",
    "    ## Learning Resources\n",
    "    [Specific courses, certifications, books, and platforms]\n",
    "    \n",
    "    ## Market Outlook\n",
    "    [Job demand, salary ranges, growth trends with data]\n",
    "    \n",
    "    ## Transition Timeline\n",
    "    [Typical timeframe for this transition based on experience level]\n",
    "    \n",
    "    ## Success Stories\n",
    "    [Brief examples of successful transitions]\n",
    "    \n",
    "    Keep your research comprehensive but concise. Focus on actionable information.\n",
    "    \"\"\",\n",
    "    tools=[google_search, preload_memory],\n",
    "    output_key=\"research_summary\",\n",
    "    after_agent_callback=auto_save_to_memory,\n",
    ")\n",
    "\n",
    "print(\"âœ… Research agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentor Agent\n",
    "mentor_agent = LlmAgent(\n",
    "    name=\"mentor_agent\",\n",
    "    model=Gemini(model=MODEL_NAME, retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "    You are a Career Mentor Agent.\n",
    "    \n",
    "    USER PROFILE:\n",
    "    {user_profile}\n",
    "    \n",
    "    RESEARCH FINDINGS:\n",
    "    {research_summary}\n",
    "    \n",
    "    Create a personalized, actionable transition plan tailored to the user's profile.\n",
    "    \n",
    "    Structure your plan:\n",
    "    \n",
    "    ## Phase 1: Foundation (Months 1-3)\n",
    "    - Specific skills to learn first (prioritized for their background)\n",
    "    - Recommended courses/resources with links\n",
    "    - Time commitment strategy (based on their available hours/week)\n",
    "    - Quick wins to build confidence\n",
    "    \n",
    "    ## Phase 2: Building Portfolio (Months 4-6)\n",
    "    - Concrete projects to build (relevant to their experience)\n",
    "    - GitHub repositories to create\n",
    "    - Communities to join (specific names)\n",
    "    - Networking strategies\n",
    "    \n",
    "    ## Phase 3: Job Search (Months 6-9)\n",
    "    - Resume updates needed\n",
    "    - Where to apply (companies, job boards)\n",
    "    - Interview preparation tips\n",
    "    - Portfolio presentation strategies\n",
    "    \n",
    "    ## Milestones & Checkpoints\n",
    "    - Monthly goals with measurable outcomes\n",
    "    - How to measure progress\n",
    "    - Red flags and when to adjust\n",
    "    \n",
    "    ## Leveraging Your Background\n",
    "    - How to translate their existing skills\n",
    "    - Unique advantages from their current position\n",
    "    - How their experience is an asset\n",
    "    \n",
    "    Be specific, realistic, and encouraging. Use actual course names and platforms.\n",
    "    Tone: supportive but practical - acknowledge challenges while emphasizing achievability.\n",
    "    \"\"\",\n",
    "    output_key=\"career_advice\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Mentor agent created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Agent - Sequential pipeline with intake loop first\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"CareerAdvisorPipeline\",\n",
    "    sub_agents=[intake_loop, research_agent, mentor_agent],\n",
    ")\n",
    "\n",
    "print(\"âœ… Root agent created with 3-stage pipeline:\")\n",
    "print(\"   1. Intake Loop (question â†’ validate â†’ repeat until complete)\")\n",
    "print(\"   2. Research Agent (gather career transition info)\")\n",
    "print(\"   3. Mentor Agent (create personalized action plan)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize services and runner\n",
    "session_service = InMemorySessionService()\n",
    "memory_service = InMemoryMemoryService()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=root_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner initialized!\")\n",
    "print(f\"   - Application: {APP_NAME}\")\n",
    "print(f\"   - User: {USER_ID}\")\n",
    "print(f\"   - Single runner for entire pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing & Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Interactive intake - Start the conversation\n",
    "# The agent will ask questions one at a time\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"I want to change careers\",\n",
    "    session_name=\"interactive-test-1\",\n",
    "    show_all_agents=True,  # Show all agents to see the loop in action\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Continue answering questions in the SAME session\n",
    "# Answer whatever the agent asked in the previous cell\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"Product Manager\",  # Example answer to \"What's your current role?\"\n",
    "    session_name=\"interactive-test-1\",  # Same session!\n",
    "    show_all_agents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Continue with more answers\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"5 years\",  # Years of experience\n",
    "    session_name=\"interactive-test-1\",\n",
    "    show_all_agents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Provide remaining info\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"Data Scientist and I can dedicate 10 hours per week\",  # Multiple pieces at once\n",
    "    session_name=\"interactive-test-1\",\n",
    "    show_all_agents=True,\n",
    ")\n",
    "# Once all info is gathered, the loop will exit and research+mentor will run automatically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: All-In-One Approach\n",
    "\n",
    "If the user provides all information upfront, the intake loop will validate and exit immediately, proceeding directly to research and mentoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Provide everything upfront (non-interactive)\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"I am a Product Manager with 5 years of experience. I want to transition to Data Science and can dedicate 10 hours per week to learning.\",\n",
    "    session_name=\"all-in-one-test\",\n",
    "    show_all_agents=False,  # Only show final mentor output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of This Approach\n",
    "\n",
    "âœ… **Single Runner** - No confusion about which runner to use\n",
    "\n",
    "âœ… **Automatic Flow** - Loop exits when profile is complete, research+mentor run automatically\n",
    "\n",
    "âœ… **Flexible** - Works for both interactive (multi-turn) and direct (all-in-one) approaches\n",
    "\n",
    "âœ… **Validated** - Can't proceed without complete, valid profile data\n",
    "\n",
    "âœ… **Memory-Aware** - Checks past conversations via preload_memory\n",
    "\n",
    "âœ… **Robust** - Max iterations prevents infinite loops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
